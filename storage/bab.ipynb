{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e378746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "y = y*2 - 1 # make y be -1 or 1\n",
    "\n",
    "# initialize a model \n",
    "model = MLP(2, [16, 16, 1]) # 2-layer neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loss function\n",
    "def loss(batch_size=None):\n",
    "    \n",
    "    # inline DataLoader :)\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "        \n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "# IBP Analysis on untrained network for a single input\n",
    "#custom_x0 = 1\n",
    "#custom_x1 = 0\n",
    "#eps = 0.1\n",
    "#input_with_bounds = [Value(custom_x0), Value(custom_x1)]\n",
    "#input_with_bounds[0].lower = input_with_bounds[0].data - eps\n",
    "#input_with_bounds[0].upper = input_with_bounds[0].data + eps\n",
    "#input_with_bounds[1].lower = input_with_bounds[1].data - eps\n",
    "#input_with_bounds[1].upper = input_with_bounds[1].data + eps\n",
    "#score = model(input_with_bounds)\n",
    "#score.ibp()\n",
    "#print(f\"Output bounds for custom input (untrained): lower={score.lower}, upper={score.upper}\")\n",
    "\n",
    "# optimization\n",
    "for k in range(20):\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    #if k % 1 == 0:\n",
    "    #print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "    \n",
    "print(f\"loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16d133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835837e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pickle file\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "import cvxpy as cp\n",
    "from micrograd.ibp import ibp, Interval\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    \n",
    "def computebounds(custom_x0, custom_x1, eps, model):\n",
    "    input_with_bounds = [Value(custom_x0), Value(custom_x1)]\n",
    "    input_with_bounds[0].lower = input_with_bounds[0].data - eps\n",
    "    input_with_bounds[0].upper = input_with_bounds[0].data + eps\n",
    "    input_with_bounds[1].lower = input_with_bounds[1].data - eps\n",
    "    input_with_bounds[1].upper = input_with_bounds[1].data + eps\n",
    "\n",
    "    score = model(input_with_bounds)\n",
    "    score.ibp()\n",
    "    return score\n",
    "\n",
    "# Collect all ReLU nodes in the computation graph of the last score\n",
    "def collect_relu_nodes(output_node):\n",
    "    relu_nodes = []\n",
    "    visited = set()\n",
    "    def traverse(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            if v._op == 'ReLU':\n",
    "                # Only add if lower and upper bounds have a sign change\n",
    "                relu_input = list(v._prev)[0]\n",
    "                lower = relu_input.lower\n",
    "                upper = relu_input.upper\n",
    "                if lower is not None and upper is not None and lower * upper < 0:\n",
    "                    relu_nodes.append(v)\n",
    "            for child in getattr(v, '_prev', []):\n",
    "                traverse(child)\n",
    "    traverse(output_node)\n",
    "    return relu_nodes\n",
    "\n",
    "  \n",
    "#score = computebounds(2, 0, 0.1, loaded_model)     \n",
    "#relu_nodes = collect_relu_nodes(score) - debugging\n",
    "\n",
    "\n",
    "def branch_and_bound(score):\n",
    "    \n",
    "    # Collect ReLU nodes\n",
    "    relu_nodes = collect_relu_nodes(score)\n",
    "    \n",
    "    # No ReLU nodes with sign change in bounds found\n",
    "    if not relu_nodes:\n",
    "        return score.lower, score.upper\n",
    "    \n",
    "    # Pick a ReLU node at random to branch on\n",
    "    chosen_relu = random.choice(relu_nodes)\n",
    "    relu_input = list(chosen_relu._prev)[0]\n",
    "    \n",
    "    \n",
    "    # Branch 1: ReLU input >= 0\n",
    "    score_branch1 = copy.deepcopy(score)\n",
    "    relu_input_pos = find_corresponding_node(score_branch1, relu_input)\n",
    "    relu_input_pos.lower = 0\n",
    "    relu_input_pos.upper = relu_input_pos.upper\n",
    "    score_branch1.ibp()\n",
    "    bounds1 = branch_and_bound(score_branch1)\n",
    "\n",
    "    # Branch 2: ReLU input <= 0\n",
    "    score_branch2 = copy.deepcopy(score)\n",
    "    relu_input_neg = find_corresponding_node(score_branch2, relu_input)\n",
    "    relu_input_neg.lower = relu_input_neg.lower\n",
    "    relu_input_neg.upper = 0\n",
    "    score_branch2.ibp()\n",
    "    bounds2 = branch_and_bound(score_branch2)\n",
    "\n",
    "    # Return global bounds\n",
    "    return min(bounds1[0], bounds2[0]), max(bounds1[1], bounds2[1])\n",
    "   \n",
    "def find_corresponding_node(new_score, old_node):\n",
    "    visited = set()\n",
    "    stack = [new_score]\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if v.id == old_node.id:\n",
    "            return v\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            if child not in visited:\n",
    "                stack.append(child)\n",
    "    raise ValueError(\"Corresponding node not found\")\n",
    "\n",
    "\n",
    "def planet_relaxation(output: Value, in_bounds: dict[Value, Interval]):\n",
    "    env = {}  # maps Value nodes to cp.Variable or float\n",
    "    constraints = []\n",
    "\n",
    "    # Traverse in topological order\n",
    "    for v in output.compute_graph():\n",
    "        if len(v.prev) == 0:\n",
    "            # Input node\n",
    "            if v in in_bounds:\n",
    "                var = cp.Variable()\n",
    "                env[v] = var\n",
    "                constraints += [\n",
    "                    var >= in_bounds[v].lower,\n",
    "                    var <= in_bounds[v].upper,\n",
    "                ]\n",
    "            else:\n",
    "                # Constant/weight node\n",
    "                env[v] = v.data\n",
    "        else:\n",
    "            # Operation node\n",
    "            if v.op == \"+\":\n",
    "                a, b = [env[p] for p in v.prev]\n",
    "                var = cp.Variable()\n",
    "                constraints.append(var == a + b)\n",
    "                env[v] = var\n",
    "            elif v.op == \"*\":\n",
    "                # For PLANET, only allow multiplication by constant (affine layers)\n",
    "                a, b = [env[p] for p in v.prev]\n",
    "                if isinstance(a, (int, float)):\n",
    "                    var = cp.Variable()\n",
    "                    constraints.append(var == a * b)\n",
    "                    env[v] = var\n",
    "                elif isinstance(b, (int, float)):\n",
    "                    var = cp.Variable()\n",
    "                    constraints.append(var == b * a)\n",
    "                    env[v] = var\n",
    "                else:\n",
    "                    #if var * var\n",
    "                    raise NotImplementedError(\"PLANET relaxation only supports multiplication by constants.\")\n",
    "            elif v.op == \"ReLU\":\n",
    "                inp = [env[p] for p in v.prev][0]\n",
    "                var = cp.Variable()\n",
    "                # Get input bounds for relaxation\n",
    "                input_node = list(v.prev)[0]\n",
    "                l = in_bounds[input_node].lower if input_node in in_bounds else input_node.lower\n",
    "                u = in_bounds[input_node].upper if input_node in in_bounds else input_node.upper\n",
    "                # Standard PLANET ReLU relaxation\n",
    "                constraints += [\n",
    "                    var >= 0,\n",
    "                    var >= inp,\n",
    "                    var <= (u / (u - l)) * (inp - l) if u > l else var <= 0,\n",
    "                    var <= u if u > 0 else var <= 0,\n",
    "                ]\n",
    "                env[v] = var\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Operation {v.op} not supported in PLANET relaxation.\")\n",
    "\n",
    "    return env, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for new ibp\n",
    "from micrograd.ibp import ibp, Interval\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "#x = tuple(map(Value, X[0]))\n",
    "x = [Value(0.5), Value(2.5)]\n",
    "in_bounds = {xi: Interval(xi.data - 0.1, xi.data + 0.1) for xi in x}\n",
    "out = loaded_model(x)\n",
    "score = ibp(out, in_bounds)\n",
    "print(out)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5533e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval(lower=np.float64(-2.6787537647437722), upper=np.float64(1.3256224613907477))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from micrograd.ibp import ibp, Interval\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "x = [Value(0), Value(0.5)]\n",
    "in_bounds = {xi: Interval(xi.data - 0.1, xi.data + 0.1) for xi in x}\n",
    "out = loaded_model(x)\n",
    "score = ibp(out, in_bounds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = computebounds(0, 0.5, 0.1, loaded_model)\n",
    "print(score.lower, score.upper)\n",
    "relu_nodes_test = collect_relu_nodes(score)\n",
    "print(f\"Number of ReLU nodes with sign change in bounds: {len(relu_nodes_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = computebounds(0, 0.5, 0.1, loaded_model)\n",
    "global_lower, global_upper = branch_and_bound(score)\n",
    "print(f\"Global lower bound: {global_lower}, Global upper bound: {global_upper}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
