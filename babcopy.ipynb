{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pickle file\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "import cvxpy as cp\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    \n",
    "def computebounds(custom_x0, custom_x1, eps, model):\n",
    "    input_with_bounds = [Value(custom_x0), Value(custom_x1)]\n",
    "    input_with_bounds[0].lower = input_with_bounds[0].data - eps\n",
    "    input_with_bounds[0].upper = input_with_bounds[0].data + eps\n",
    "    input_with_bounds[1].lower = input_with_bounds[1].data - eps\n",
    "    input_with_bounds[1].upper = input_with_bounds[1].data + eps\n",
    "\n",
    "    score = model(input_with_bounds)\n",
    "    score.ibp()\n",
    "    return score\n",
    "\n",
    "#new dic for if already split on / or relu\n",
    "\n",
    "# Collect all ReLU nodes in the computation graph of the last score\n",
    "def collect_relu_nodes(output_node):\n",
    "    relu_nodes = []\n",
    "    visited = set()\n",
    "    def traverse(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            if v._op == 'ReLU':\n",
    "                # Only add if lower and upper bounds have a sign change\n",
    "                relu_input = list(v._prev)[0]\n",
    "                lower = relu_input.lower\n",
    "                upper = relu_input.upper\n",
    "                if lower is not None and upper is not None and lower * upper < 0:\n",
    "                    relu_nodes.append(v)\n",
    "            for child in getattr(v, '_prev', []):\n",
    "                traverse(child)\n",
    "    traverse(output_node)\n",
    "    return relu_nodes\n",
    "\n",
    "  \n",
    "#score = computebounds(2, 0, 0.1, loaded_model)     \n",
    "#relu_nodes = collect_relu_nodes(score) - debugging\n",
    "\n",
    "\n",
    "def branch_and_bound(score):\n",
    "    \n",
    "    # Collect ReLU nodes\n",
    "    relu_nodes = collect_relu_nodes(score)\n",
    "    \n",
    "    # No ReLU nodes with sign change in bounds found\n",
    "    if not relu_nodes:\n",
    "        return score.lower, score.upper\n",
    "    \n",
    "    # Pick a ReLU node at random to branch on\n",
    "    #chosen_relu = random.choice(relu_nodes)\n",
    "    chosen_relu = relu_nodes[7]  # For deterministic behavior, use the first one\n",
    "    relu_input = list(chosen_relu._prev)[0]\n",
    "    \n",
    "    \n",
    "    # Branch 1: ReLU input >= 0\n",
    "    score_branch1 = copy.deepcopy(score)\n",
    "    relu_input_pos = find_corresponding_node(score_branch1, relu_input)\n",
    "    relu_input_pos.lower = 0\n",
    "    relu_input_pos.chosen_relu = True  # Mark as chosen for this branch\n",
    "    score_branch1.ibp()\n",
    "    \n",
    "    # Check if the bounds are valid for the first branch via Planet relaxation\n",
    "    check1_l, check1_u = planet_relaxation(score_branch1)\n",
    "    #print(f\"check1_l: {check1_l}, check1_u: {check1_u}\")  # debugging\n",
    "    if check1_l >=0:\n",
    "        print(f\"check1_l: {check1_l}, check1_u: {check1_u}\")\n",
    "        return score_branch1.lower, score_branch1.upper\n",
    "    elif check1_u < 0:\n",
    "        raise ValueError(\"Relaxation bounds are not valid.\") \n",
    "    elif check1_l == 'inf' or check1_u == '-inf':\n",
    "        return 'inf', '-inf'\n",
    "    \n",
    "    bounds1 = branch_and_bound(score_branch1)\n",
    "\n",
    "#inf and -inf for planet infesibable\n",
    "\n",
    "\n",
    "    # Branch 2: ReLU input <= 0\n",
    "    score_branch2 = copy.deepcopy(score)\n",
    "    relu_input_neg = find_corresponding_node(score_branch2, relu_input)\n",
    "    relu_input_neg.upper = 0\n",
    "    relu_input_neg.chosen_relu = True  # Mark as chosen for this branch\n",
    "    score_branch2.ibp()\n",
    "    \n",
    "    # Check if the bounds are valid for the second branch via Planet relaxation\n",
    "    check2_l, check2_u = planet_relaxation(score_branch2)\n",
    "    if check2_l >= 0:\n",
    "        return score_branch2.lower, score_branch2.upper\n",
    "    elif check2_u < 0:\n",
    "        raise ValueError(\"Relaxation bounds are not valid.\")\n",
    "    elif check2_l == 'inf' or check2_u == '-inf':\n",
    "        return 'inf', '-inf'\n",
    "    \n",
    "    \n",
    "    bounds2 = branch_and_bound(score_branch2)\n",
    "\n",
    "    # Return global bounds\n",
    "    print (f\"bounds1: {bounds1}, bounds2: {bounds2}\")  # debugging\n",
    "    return min(bounds1[0], bounds2[0]), max(bounds1[1], bounds2[1])\n",
    "   \n",
    "def find_corresponding_node(new_score, old_node):\n",
    "    visited = set()\n",
    "    stack = [new_score]\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if v.id == old_node.id:\n",
    "            return v\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            if child not in visited:\n",
    "                stack.append(child)\n",
    "    raise ValueError(\"Corresponding node not found\")\n",
    "\n",
    "\n",
    "def planet_relaxation(output: Value):\n",
    "    env = {}  # maps Value nodes to cp.Variable or float\n",
    "    constraints = []\n",
    "\n",
    "    # Traverse in topological order\n",
    "    for v in output.compute_graph():\n",
    "        if len(v._prev) == 0:\n",
    "            # Input node\n",
    "            if (v.input):\n",
    "                #alternavit to lower != data \n",
    "                #(v.lower == -0.1 and v.upper == 0.1) or (v.lower == 0.4 and v.upper == 0.6)\n",
    "                var = cp.Variable()\n",
    "                env[v] = var\n",
    "                constraints += [\n",
    "                    var >= v.lower,\n",
    "                    var <= v.upper,\n",
    "                ]\n",
    "            else:\n",
    "                # Constant/weight node\n",
    "                #print(f\"Assigning constant: {v}, value type: {type(v.data)}\") #debugging\n",
    "                env[v] = v.data\n",
    "        else:\n",
    "            # Operation node\n",
    "            if v._op == \"+\":\n",
    "                a, b = [env[p] for p in v._prev]\n",
    "                var = cp.Variable()\n",
    "                constraints.append(var == a + b)\n",
    "                env[v] = var\n",
    "            elif v._op == \"*\":\n",
    "                # For PLANET, only allow multiplication by constant (affine layers)\n",
    "                a, b = [env[p] for p in v._prev]\n",
    "                #print(f\"Multiplying types: {type(a)}, {type(b)}\") #debugging\n",
    "                \n",
    "                if isinstance(a, (int, float)):\n",
    "                    var = cp.Variable()\n",
    "                    constraints.append(var == a * b)\n",
    "                    env[v] = var\n",
    "                elif isinstance(b, (int, float)):\n",
    "                    var = cp.Variable()\n",
    "                    constraints.append(var == b * a)\n",
    "                    env[v] = var\n",
    "                else:\n",
    "                    #if var * var\n",
    "                    raise NotImplementedError(\"PLANET relaxation only supports multiplication by constants.\")\n",
    "            \n",
    "            elif v._op == \"ReLU\":\n",
    "                inp = [env[p] for p in v._prev][0]\n",
    "                var = cp.Variable()\n",
    "                # Get input bounds for relaxation\n",
    "                input_node = list(v._prev)[0]\n",
    "                l = input_node.lower\n",
    "                u = input_node.upper\n",
    "                # Standard PLANET ReLU relaxation\n",
    "                constraints += [\n",
    "                    var >= 0,\n",
    "                    var >= inp,\n",
    "                    var <= (u / (u - l)) * (inp - l) if u > l else var <= 0,\n",
    "                    var <= u if u > 0 else var <= 0,\n",
    "                ]\n",
    "                env[v] = var\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Operation {v.op} not supported in PLANET relaxation.\")\n",
    "\n",
    "    prob_lower = cp.Problem(cp.Minimize(env[output]), constraints)\n",
    "    result_lower = prob_lower.solve()\n",
    "    \n",
    "    prob_upper = cp.Problem(cp.Maximize(env[output]), constraints)\n",
    "    result_upper = prob_upper.solve()\n",
    "    \n",
    "    return result_lower , result_upper\n",
    "\n",
    "\n",
    "\n",
    "score = computebounds(0, 0.5, 0.1, loaded_model)\n",
    "global_lower, global_upper = branch_and_bound(score)\n",
    "print(f\"Global lower bound: {global_lower}, Global upper bound: {global_upper}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
