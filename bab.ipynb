{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e378746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "y = y*2 - 1 # make y be -1 or 1\n",
    "\n",
    "# initialize a model \n",
    "model = MLP(2, [16, 16, 1]) # 2-layer neural network\n",
    "\n",
    "\n",
    "# loss function\n",
    "def loss(batch_size=None):\n",
    "    \n",
    "    # inline DataLoader :)\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "        \n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "# IBP Analysis on untrained network for a single input\n",
    "#custom_x0 = 1\n",
    "#custom_x1 = 0\n",
    "#eps = 0.1\n",
    "#input_with_bounds = [Value(custom_x0), Value(custom_x1)]\n",
    "#input_with_bounds[0].lower = input_with_bounds[0].data - eps\n",
    "#input_with_bounds[0].upper = input_with_bounds[0].data + eps\n",
    "#input_with_bounds[1].lower = input_with_bounds[1].data - eps\n",
    "#input_with_bounds[1].upper = input_with_bounds[1].data + eps\n",
    "#score = model(input_with_bounds)\n",
    "#score.ibp()\n",
    "#print(f\"Output bounds for custom input (untrained): lower={score.lower}, upper={score.upper}\")\n",
    "\n",
    "# optimization\n",
    "for k in range(100):\n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    #if k % 1 == 0:\n",
    "    #print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "    \n",
    "print(f\"loss {total_loss.data}, accuracy {acc*100}%\")\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16d133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from pickle file\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP\n",
    "import cvxpy as cp\n",
    "\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    \n",
    "def computebounds(custom_x0, custom_x1, eps, model):\n",
    "    input_with_bounds = [Value(custom_x0), Value(custom_x1)]\n",
    "    input_with_bounds[0].lower = input_with_bounds[0].data - eps\n",
    "    input_with_bounds[0].upper = input_with_bounds[0].data + eps\n",
    "    input_with_bounds[1].lower = input_with_bounds[1].data - eps\n",
    "    input_with_bounds[1].upper = input_with_bounds[1].data + eps\n",
    "\n",
    "    score = model(input_with_bounds)\n",
    "    score.ibp()\n",
    "    return score\n",
    "\n",
    "# Collect all ReLU nodes in the computation graph of the last score\n",
    "def collect_relu_nodes(output_node):\n",
    "    relu_nodes = []\n",
    "    visited = set()\n",
    "    def traverse(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            if v._op == 'ReLU':\n",
    "                # Only add if lower and upper bounds have a sign change\n",
    "                relu_input = list(v._prev)[0]\n",
    "                lower = relu_input.lower\n",
    "                upper = relu_input.upper\n",
    "                if lower is not None and upper is not None and lower * upper < 0:\n",
    "                    relu_nodes.append(v)\n",
    "            for child in getattr(v, '_prev', []):\n",
    "                traverse(child)\n",
    "    traverse(output_node)\n",
    "    return relu_nodes\n",
    "\n",
    "  \n",
    "#score = computebounds(2, 0, 0.1, loaded_model)     \n",
    "#relu_nodes = collect_relu_nodes(score) - debugging\n",
    "\n",
    "\n",
    "def branch_and_bound(score):\n",
    "    \n",
    "    # Collect ReLU nodes\n",
    "    relu_nodes = collect_relu_nodes(score)\n",
    "    \n",
    "    # No ReLU nodes with sign change in bounds found\n",
    "    if not relu_nodes:\n",
    "        return score.lower, score.upper\n",
    "    \n",
    "    # Pick a ReLU node at random to branch on\n",
    "    chosen_relu = random.choice(relu_nodes)\n",
    "    relu_input = list(chosen_relu._prev)[0]\n",
    "    \n",
    "    \n",
    "    # Branch 1: ReLU input >= 0\n",
    "    score_branch1 = copy.deepcopy(score)\n",
    "    relu_input_pos = find_corresponding_node(score_branch1, relu_input)\n",
    "    relu_input_pos.lower = 0\n",
    "    relu_input_pos.upper = relu_input_pos.upper\n",
    "    score_branch1.ibp()\n",
    "    bounds1 = branch_and_bound(score_branch1)\n",
    "\n",
    "    # Branch 2: ReLU input <= 0\n",
    "    score_branch2 = copy.deepcopy(score)\n",
    "    relu_input_neg = find_corresponding_node(score_branch2, relu_input)\n",
    "    relu_input_neg.lower = relu_input_neg.lower\n",
    "    relu_input_neg.upper = 0\n",
    "    score_branch2.ibp()\n",
    "    bounds2 = branch_and_bound(score_branch2)\n",
    "\n",
    "    # Return global bounds\n",
    "    return min(bounds1[0], bounds2[0]), max(bounds1[1], bounds2[1])\n",
    "   \n",
    "def find_corresponding_node(new_score, old_node):\n",
    "    visited = set()\n",
    "    stack = [new_score]\n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        if v.id == old_node.id:\n",
    "            return v\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            if child not in visited:\n",
    "                stack.append(child)\n",
    "    raise ValueError(\"Corresponding node not found\")\n",
    "\n",
    "\n",
    "def planet_relaxation(score):\n",
    "    # Collect ReLU nodes\n",
    "    relu_nodes = collect_relu_nodes(score)\n",
    "    \n",
    "    if not relu_nodes:\n",
    "        return score.lower, score.upper\n",
    "    \n",
    "    # Create a list of constraints\n",
    "    constraints = []\n",
    "    \n",
    "    for relu_node in relu_nodes:\n",
    "        relu_input = list(relu_node._prev)[0]\n",
    "        lower_bound = relu_input.lower\n",
    "        upper_bound = relu_input.upper\n",
    "        \n",
    "        if lower_bound is not None and upper_bound is not None:\n",
    "            # Add constraints for the ReLU node\n",
    "            constraints.append(cp.constraints.NonPos(relu_input - 0))\n",
    "    \n",
    "    # Define the optimization problem\n",
    "    objective = cp.Minimize(0)  # No specific objective, just bounds\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve()\n",
    "    \n",
    "    return score.lower, score.upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec4a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1302737934450184 1.3347824065425349\n",
      "Number of ReLU nodes with sign change in bounds: 9\n"
     ]
    }
   ],
   "source": [
    "score = computebounds(0, 0.5, 0.1, loaded_model)\n",
    "print(score.lower, score.upper)\n",
    "relu_nodes_test = collect_relu_nodes(score)\n",
    "print(f\"Number of ReLU nodes with sign change in bounds: {len(relu_nodes_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98f1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global lower bound: -2.1302737934450184, Global upper bound: 1.3347824065425349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = computebounds(0, 0.5, 0.1, loaded_model)\n",
    "global_lower, global_upper = branch_and_bound(score)\n",
    "print(f\"Global lower bound: {global_lower}, Global upper bound: {global_upper}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
